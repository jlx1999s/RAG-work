#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•æµ‹è¯•RAGGraph invokeæ–¹æ³•
åˆå§‹åŒ–å‘é‡æ¨¡å‹å’Œå¤§æ¨¡å‹ï¼Œç„¶åè°ƒç”¨invoke API
"""

import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from backend.agent.models import (
    load_chat_model,
    load_embeddings,
    register_embeddings_provider,
    register_model_provider
)
from backend.agent.graph import RAGGraph
from backend.agent.contexts.raggraph_context import RAGContext
from backend.config.log import setup_default_logging, get_logger
from langchain_qwq import ChatQwen
# åˆå§‹åŒ–æ—¥å¿—
setup_default_logging()
logger = get_logger(__name__)

def init_models():
    """åˆå§‹åŒ–å¤§æ¨¡å‹å’Œå‘é‡æ¨¡å‹"""
    logger.info("å¼€å§‹åˆå§‹åŒ–æ¨¡å‹...")
    
    register_model_provider(
        provider_name="qwen",
        chat_model=ChatQwen
    )

    chat_model = load_chat_model(
        "qwen:qwen3-max-preview"
    )
    logger.info(f"å¤§æ¨¡å‹åŠ è½½æˆåŠŸ: {type(chat_model)}")
    
    # 2. æ³¨å†Œå¹¶åŠ è½½å‘é‡æ¨¡å‹ (é˜¿é‡Œäº‘)
    logger.info("æ³¨å†Œå‘é‡æ¨¡å‹æä¾›å•†...")
    register_embeddings_provider(
        provider_name="ali",
        embeddings_model="openai",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )
    
    logger.info("åŠ è½½å‘é‡æ¨¡å‹...")
    embeddings_model = load_embeddings(
        "ali:text-embedding-v4",
        api_key="sk-",
        check_embedding_ctx_length=False,
        dimensions=1536
    )
    logger.info(f"å‘é‡æ¨¡å‹åŠ è½½æˆåŠŸ: {type(embeddings_model)}")
    
    return chat_model, embeddings_model

def test_raggraph_invoke():
    """æµ‹è¯•RAGGraphçš„invokeæ–¹æ³•"""
    logger.info("å¼€å§‹æµ‹è¯•RAGGraph invokeæ–¹æ³•...")
    
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        chat_model, embeddings_model = init_models()
        
        # åˆ›å»ºRAGGraphå®ä¾‹
        logger.info("åˆ›å»ºRAGGraphå®ä¾‹...")
        rag_graph = RAGGraph(llm=chat_model, embedding_model=embeddings_model)
        logger.info("RAGGraphå®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºRAGä¸Šä¸‹æ–‡
        logger.info("åˆ›å»ºRAGä¸Šä¸‹æ–‡...")
        context = RAGContext(
            session_id="tessasaasasassas2",
            user_id="test_user_020",
            retrieval_mode="no_retrieval"
        )
        logger.info("RAGä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ")
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        input_data = {
            "messages": [
                {"role": "user", "content": "æˆ‘ä¸Šä¸€ä¸ªé—®é¢˜æ˜¯ä»€ä¹ˆ"}
            ]
        }
        logger.info(f"è¾“å…¥é—®é¢˜: {input_data['messages'][0]['content']}")
        
        # è°ƒç”¨invokeæ–¹æ³•
        logger.info("è°ƒç”¨RAGGraph.invokeæ–¹æ³•...")
        result = rag_graph.invoke(input_data, context)

        # è¾“å‡ºç»“æœ
        logger.info("RAGGraph invokeè°ƒç”¨æˆåŠŸ!")
        #logger.info(f"ç»“æœç±»å‹: {type(result)}")

        logger.info(f"æœ€ç»ˆç­”æ¡ˆ: {result}")

        return result
        
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        raise

def test_raggraph_stream():
    """æµ‹è¯•RAGGraphçš„streamæµå¼è¾“å‡ºæ–¹æ³•"""
    logger.info("å¼€å§‹æµ‹è¯•RAGGraph streamæµå¼è¾“å‡º...")

    try:
        # åˆå§‹åŒ–æ¨¡å‹
        chat_model, embeddings_model = init_models()

        # åˆ›å»ºRAGGraphå®ä¾‹
        logger.info("åˆ›å»ºRAGGraphå®ä¾‹...")
        rag_graph = RAGGraph(llm=chat_model, embedding_model=embeddings_model)
        logger.info("RAGGraphå®ä¾‹åˆ›å»ºæˆåŠŸ")

        # # åˆ›å»ºRAGä¸Šä¸‹æ–‡
        # logger.info("åˆ›å»ºRAGä¸Šä¸‹æ–‡...")
        # context = RAGContext(
        #     session_id="test_stream_session_0011",
        #     user_id="test_user_stream"
        # )
        # logger.info("RAGä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ")

        # # å‡†å¤‡è¾“å…¥æ•°æ®
        # input_data = {
        #     "messages": [
        #         {"role": "user", "content": "è¯·ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹"}
        #     ]
        # }
        # logger.info(f"è¾“å…¥é—®é¢˜: {input_data['messages'][0]['content']}")

        final_result = None

        # æ–¹æ³•1: ä½¿ç”¨ stream_mode="updates" æŸ¥çœ‹èŠ‚ç‚¹æ›´æ–°
        # logger.info("ğŸ”„ æ–¹æ³•1: èŠ‚ç‚¹æ›´æ–°æµå¼è¾“å‡º (stream_mode='updates')")
        

        # for chunk in rag_graph.stream(input_data, context, stream_mode="updates"):
        #     print(chunk)
        #     print("\n")

        # æ–¹æ³•2: ä½¿ç”¨ stream_mode="values" æŸ¥çœ‹å®Œæ•´çŠ¶æ€
        # logger.info("="*60)
        # logger.info("ğŸ”„ æ–¹æ³•2: å®Œæ•´çŠ¶æ€æµå¼è¾“å‡º (stream_mode='values')")

        # # ä½¿ç”¨æ–°çš„ä¼šè¯IDé¿å…å†²çª
        # context_values = RAGContext(
        #     session_id="test_stream_values_0501",
        #     user_id="test_user_stream"
        # )

        # input_data_values = {
        #     "messages": [
        #         {"role": "user", "content": "1+1ç­‰äºå¤šå°‘ï¼Ÿ"}
        #     ]
        # }

        # for state_snapshot in rag_graph.stream(input_data_values, context_values, stream_mode="values"):
        #     logger.info(f"çŠ¶æ€å¿«ç…§: {state_snapshot}")

        # æ–¹æ³•3: å¦‚æœæ”¯æŒï¼Œå°è¯•ä½¿ç”¨ stream_mode="messages" è·å–LLM token
        # logger.info("\n" + "="*60)
        # logger.info("ğŸ”„ æ–¹æ³•3: LLM Tokenæµå¼è¾“å‡º (stream_mode='messages')")

        # # ä½¿ç”¨æ–°çš„ä¼šè¯IDé¿å…å†²çª
        # context_values = RAGContext(
        #     session_id="test_stream_valuess_01",
        #     user_id="test_user_stream"
        # )

        # input_data_messages = {
        #     "messages": [
        #         {"role": "user", "content": "ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹"}
        #     ]
        # }

        # for state_snapshot in rag_graph.stream(input_data_messages, context_values, stream_mode="values"):
        #     logger.info(f"çŠ¶æ€å¿«ç…§: {state_snapshot}")

        # æ–¹æ³•3: å¦‚æœæ”¯æŒï¼Œå°è¯•ä½¿ç”¨ stream_mode="messages" è·å–LLM token
        # logger.info("\n" + "="*60)
        # logger.info("ğŸ”„ æ–¹æ³•3: LLM Tokenæµå¼è¾“å‡º (stream_mode='messages')")

        context_messages = RAGContext(
            session_id="tesessasssge1s_01",
            user_id="test_user_stresam"
        )

        input_data_messages = {
            "messages": [
                {"role": "user", "content": "æŸ¥æ‰¾çŸ¥è¯†åº“ä¸ºæˆ‘ä»‹ç»istio"}
            ]
        }

        logger.info("ğŸ¯ å°è¯•æ•è·LLM tokenæµ...")
        
        
        for mode,chunk in rag_graph.stream(input_data_messages, context_messages, stream_mode="mix"):
            if mode == "updates":
                node_name = list(chunk.keys())[0]
                print(f"èŠ‚ç‚¹åç§°: {node_name}")
                if node_name == "generate_answer" or node_name == "direct_answer":
                    print(f"{chunk}")
            if mode == "messages":
                chunkmessage,metadata=chunk
                if chunkmessage.content:
                    print(f"æ¶ˆæ¯: {chunkmessage.content}")
            #     if chunkmessage.content and len(chunkmessage.content.strip())<=10:
            #         print(f"æ¶ˆæ¯: {chunkmessage.content}")
            #         #print(f"å…ƒæ•°æ®: {metadata}")
        

        # for mode,chunk in rag_graph.stream(input_data_messages, context_messages, stream_mode="mix"):
        #     # print(metadata)
        #     # print(chunk)
        #     # print(f"[{mode}]")
        #     if mode == "updates":
        #         # æ˜¾ç¤ºèŠ‚ç‚¹åç§°
                
        #         node_name = list(chunk.keys())[0]
        #         node_output = chunk[node_name]
        #         print(f"èŠ‚ç‚¹åç§°: {node_name}")
        #         print(f"èŠ‚ç‚¹è¾“å‡º: {node_output}")
        #     print("============")
        #     if mode == "messages":
        #         chunkmessage,metadata=chunk
        #         print(f"æ¶ˆæ¯: {chunkmessage}")
        #     #     if chunkmessage.content and len(chunkmessage.content.strip())<=10:
        #     #         print(f"æ¶ˆæ¯: {chunkmessage.content}")
        #     #         #print(f"å…ƒæ•°æ®: {metadata}")

                            

        return final_result

    except Exception as e:
        logger.error(f"æµå¼è¾“å‡ºæµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        raise

if __name__ == "__main__":
    logger.info("=" * 80)
    logger.info("å¼€å§‹RAGGraphæµ‹è¯•")
    logger.info("=" * 80)

    try:
        # æµ‹è¯•1: invokeæ–¹æ³•
        # logger.info("\n" + "=" * 50)
        logger.info("æµ‹è¯•1: invokeæ–¹æ³•")
        logger.info("=" * 50)
        #result1 = test_raggraph_invoke()

        # æµ‹è¯•2: streamæµå¼è¾“å‡ºæ–¹æ³•
        # logger.info("\n" + "=" * 50)
        # logger.info("æµ‹è¯•2: streamæµå¼è¾“å‡ºæ–¹æ³•")
        # logger.info("=" * 50)
        result2 = test_raggraph_stream()

        logger.info("\n" + "=" * 80)
        logger.info("æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        # logger.info("=" * 80)
        # logger.info("æµ‹è¯•æ€»ç»“:")
        # logger.info(f"1. invokeæ–¹æ³•æµ‹è¯•: {'æˆåŠŸ' if result1 else 'å¤±è´¥'}")
        #logger.info(f"2. streamæ–¹æ³•æµ‹è¯•: {'æˆåŠŸ' if result2 else 'å¤±è´¥'}")

    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {str(e)}")
        exit(1)